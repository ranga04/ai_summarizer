{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Install the Necessary Libraries\\\n",
        "We need to install Whisper (for transcription), OpenAI (for summarization and question generation), and some other helper libraries."
      ],
      "metadata": {
        "id": "XJXyOBjL6cl_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-siCPTG59Ld"
      },
      "outputs": [],
      "source": [
        "# Install Whisper for transcribing audio\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# Install OpenAI API for summarization and question generation\n",
        "!pip install openai\n",
        "\n",
        "# Install yake for keyword extraction\n",
        "!pip install yake\n",
        "\n",
        "# Install transformers for sentiment analysis\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Transcribing the Lecture Using Whisper\\\n",
        "Explanation:\n",
        "\n",
        "Whisper is an AI model that listens to audio files and converts them into text. We will use this to transcribe the lecture from an audio file (e.g., lecture.mp3).\n",
        "\n",
        "In case the audio is on Google Drive, we will access it from there."
      ],
      "metadata": {
        "id": "Uv0B1kjJ6lVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import whisper\n",
        "import openai\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access files (if the audio is stored there)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the Whisper model (we use the 'base' model here, but there are larger ones for more accuracy)\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcribe the audio\n",
        "audio_file = '/content/drive/MyDrive/lecture.mp3'  # Change to the file location\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "# Get the transcription\n",
        "transcription = result['text']\n",
        "print(\"Transcription:\\n\", transcription)\n"
      ],
      "metadata": {
        "id": "uQ5S02mh67om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Summarizing the Transcription Using GPT-3\\\n",
        "Explanation:\n",
        "\n",
        "Now that we have the transcription, we will use GPT-3 to summarize it. GPT-3 is a powerful language model from OpenAI that can take large chunks of text and turn them into shorter summaries."
      ],
      "metadata": {
        "id": "aF7K0uzE7DMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the OpenAI API key (get one from https://beta.openai.com/signup/)\n",
        "openai.api_key = 'openai_api_key_here'\n",
        "\n",
        "# Function to summarize a text using GPT-3\n",
        "def summarize_text(text):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",  # GPT-3 model\n",
        "        prompt=f\"Summarize this lecture transcript:\\n\\n{text}\",\n",
        "        max_tokens=150,  # Length of the summary\n",
        "        temperature=0.5  # Controls randomness\n",
        "    )\n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "\n",
        "# Summarize the transcription\n",
        "summary = summarize_text(transcription)\n",
        "print(\"Summary:\\n\", summary)\n"
      ],
      "metadata": {
        "id": "8hO-7_vt7HDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Extracting Keywords and Generating Questions\\\n",
        "Explanation:\n",
        "\n",
        "Keywords help identify the main points of the lecture.\n",
        "Quiz questions can be generated from the summary to test understanding, making this a great learning tool."
      ],
      "metadata": {
        "id": "KnhF6WUS7yV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import yake for keyword extraction\n",
        "import yake\n",
        "\n",
        "# Initialize the keyword extractor\n",
        "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=10)  # Extract top 10 keywords\n",
        "\n",
        "# Function to extract keywords\n",
        "def extract_keywords(text):\n",
        "    keywords = kw_extractor.extract_keywords(text)\n",
        "    return [kw for kw, score in keywords]\n",
        "\n",
        "# Extract keywords from the transcription\n",
        "keywords = extract_keywords(transcription)\n",
        "print(\"Keywords:\\n\", keywords)\n"
      ],
      "metadata": {
        "id": "LCQu1uDl73O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate questions from the summary\n",
        "def generate_questions(summary):\n",
        "    prompt = f\"Generate 3 questions based on the following summary:\\n\\n{summary}\\n\\nQuestions:\"\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        temperature=0.5\n",
        "    )\n",
        "    questions = response.choices[0].text.strip()\n",
        "    return questions\n",
        "\n",
        "# Generate questions for the summary\n",
        "questions = generate_questions(summary)\n",
        "print(\"Quiz Questions:\\n\", questions)\n"
      ],
      "metadata": {
        "id": "r3RXF2pZ7_bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 5: Sentiment Analysis\\\n",
        "Explanation:\n",
        "\n",
        "Sentiment analysis detects the tone or emotion in the text. It can be useful to understand the mood of different parts of the lecture."
      ],
      "metadata": {
        "id": "D71BTTZf8DuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import sentiment analysis from transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the sentiment analysis model\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Analyze sentiment of the full transcription\n",
        "sentiment = sentiment_analyzer(transcription[:500])  # Analyze only the first 500 characters for speed\n",
        "print(\"Sentiment Analysis:\\n\", sentiment)\n"
      ],
      "metadata": {
        "id": "NeOIGbG-8HLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}